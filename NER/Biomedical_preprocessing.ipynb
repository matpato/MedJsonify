{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download required NLTK resources\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wEVnpCFcgQz",
        "outputId": "433a3b0a-032e-40ce-b30e-f25ca86bdd66",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common biomedical abbreviations and their expanded forms\n",
        "bio_abbreviations = {\n",
        "    \"AD\": \"Alzheimer's disease\",\n",
        "    \"MI\": \"myocardial infarction\",\n",
        "    \"HTN\": \"hypertension\",\n",
        "    \"DM\": \"diabetes mellitus\",\n",
        "    \"CHF\": \"congestive heart failure\",\n",
        "    \"COPD\": \"chronic obstructive pulmonary disease\",\n",
        "    \"RA\": \"rheumatoid arthritis\",\n",
        "    \"MS\": \"multiple sclerosis\",\n",
        "    \"ASMD\": \"ASM-deficient Niemann-Pick disease\",\n",
        "    # Add more as needed\n",
        "}\n",
        "\n",
        "# Common misspellings of drug names\n",
        "drug_spelling_corrections = {\n",
        "    \"acetaminophen\": [\"acetaminophen\", \"acetaminophine\", \"acetaminofin\"],\n",
        "    \"ibuprofen\": [\"ibuprofen\", \"ibuprofin\", \"ibuprophen\"],\n",
        "    \"amoxicillin\": [\"amoxicillin\", \"amoxicilin\", \"amoxicillan\"],\n",
        "    # Add more as needed\n",
        "}\n",
        "\n",
        "# Create reverse mapping for drug spelling corrections\n",
        "drug_spelling_map = {}\n",
        "for correct, variants in drug_spelling_corrections.items():\n",
        "    for variant in variants:\n",
        "        if variant != correct:\n",
        "            drug_spelling_map[variant] = correct"
      ],
      "metadata": {
        "id": "yUYHbsBScqND"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_encoding_issues(text):\n",
        "    \"\"\"\n",
        "    Fix common encoding issues in text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text with potential encoding issues\n",
        "\n",
        "    Returns:\n",
        "        str: Text with fixed encoding issues\n",
        "    \"\"\"\n",
        "    # Replace common problematic characters\n",
        "    replacements = {\n",
        "        '\\x92': \"'\",    # Right single quotation mark\n",
        "        '\\x93': '\"',    # Left double quotation mark\n",
        "        '\\x94': '\"',    # Right double quotation mark\n",
        "        '\\x96': '-',    # En dash\n",
        "        '\\x97': '-',    # Em dash\n",
        "        '\\xa0': ' ',    # Non-breaking space\n",
        "        '&amp;': '&',   # HTML ampersand\n",
        "        '&lt;': '<',    # HTML less than\n",
        "        '&gt;': '>',    # HTML greater than\n",
        "    }\n",
        "\n",
        "    for old, new in replacements.items():\n",
        "        text = text.replace(old, new)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "dBNpst6Ycybp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_punctuation(text, keep_punctuation=True):\n",
        "    \"\"\"\n",
        "    Standardize punctuation in text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        keep_punctuation (bool): Whether to keep biomedically relevant punctuation\n",
        "\n",
        "    Returns:\n",
        "        str: Text with standardized punctuation\n",
        "    \"\"\"\n",
        "    if keep_punctuation:\n",
        "        # Replace multiple dashes with single dash (but keep the dash)\n",
        "        text = re.sub(r'-+', '-', text)\n",
        "\n",
        "        # Ensure spaces around punctuation except for specific cases\n",
        "        # Keep punctuation in patterns like \"COVID-19\", \"5-HTP\", \"50mg\"\n",
        "        for punct in [',', '.', ';', ':', '!', '?']:\n",
        "            text = re.sub(f'(?<![A-Za-z0-9]){re.escape(punct)}', f' {punct} ', text)\n",
        "\n",
        "        # Standardize parentheses with spaces\n",
        "        text = re.sub(r'\\(', ' ( ', text)\n",
        "        text = re.sub(r'\\)', ' ) ', text)\n",
        "\n",
        "        # Fix spaces\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "    else:\n",
        "        # Remove punctuation entirely (not recommended for biomedical NER)\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "TADyOeO5c3Aa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_case(text, preserve_case=False):\n",
        "    \"\"\"\n",
        "    Normalize the case of text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        preserve_case (bool): Whether to preserve the original case\n",
        "\n",
        "    Returns:\n",
        "        str: Text with normalized case\n",
        "    \"\"\"\n",
        "    if not preserve_case:\n",
        "        text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "7kfHp1kRke3_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_abbreviations(text, abbreviations=bio_abbreviations):\n",
        "    \"\"\"\n",
        "    Expand common biomedical abbreviations.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        abbreviations (dict): Dictionary of abbreviations and their expanded forms\n",
        "\n",
        "    Returns:\n",
        "        str: Text with expanded abbreviations\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    for i, word in enumerate(words):\n",
        "        # Check if word is a known abbreviation (as a standalone word)\n",
        "        if word in abbreviations:\n",
        "            # Replace with the expanded form\n",
        "            words[i] = abbreviations[word]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "vYGODj1akhVa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_drug_spelling(text, spelling_map=drug_spelling_map):\n",
        "    \"\"\"\n",
        "    Correct common misspellings of drug names.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        spelling_map (dict): Dictionary mapping misspelled drugs to their correct spelling\n",
        "\n",
        "    Returns:\n",
        "        str: Text with corrected drug spellings\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    for i, word in enumerate(words):\n",
        "        lower_word = word.lower()\n",
        "        if lower_word in spelling_map:\n",
        "            # Replace with correct spelling but preserve case pattern\n",
        "            if word.isupper():\n",
        "                words[i] = spelling_map[lower_word].upper()\n",
        "            elif word[0].isupper():\n",
        "                words[i] = spelling_map[lower_word].capitalize()\n",
        "            else:\n",
        "                words[i] = spelling_map[lower_word]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "aACvyUbYkj0f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text, standard_stopwords, custom_stopwords=None):\n",
        "    \"\"\"\n",
        "    Remove stopwords from text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        standard_stopwords (set): Set of standard stopwords\n",
        "        custom_stopwords (list, optional): List of custom stopwords\n",
        "\n",
        "    Returns:\n",
        "        str: Text with stopwords removed\n",
        "    \"\"\"\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Filter out standard stopwords\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in standard_stopwords]\n",
        "\n",
        "    # Filter out custom stopwords if provided\n",
        "    if custom_stopwords:\n",
        "        custom_stopwords_lower = [word.lower() for word in custom_stopwords]\n",
        "        filtered_tokens = [token for token in filtered_tokens\n",
        "                          if token.lower() not in custom_stopwords_lower]\n",
        "\n",
        "    # Join tokens back into text\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "dcmQsQtGkmY3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, preserve_case=False, keep_punctuation=True,\n",
        "                   remove_stops=True, custom_stopwords=None):\n",
        "    \"\"\"\n",
        "    Apply all preprocessing steps to the input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text\n",
        "        preserve_case (bool): Whether to preserve the original case\n",
        "        keep_punctuation (bool): Whether to keep biomedically relevant punctuation\n",
        "        remove_stops (bool): Whether to remove stopwords\n",
        "        custom_stopwords (list): Custom stopwords to remove\n",
        "\n",
        "    Returns:\n",
        "        str: Fully preprocessed text\n",
        "    \"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Apply preprocessing steps in sequence\n",
        "    text = fix_encoding_issues(text)\n",
        "    text = standardize_punctuation(text, keep_punctuation)\n",
        "\n",
        "    if not preserve_case:\n",
        "        text = normalize_case(text)\n",
        "\n",
        "    text = expand_abbreviations(text)\n",
        "    text = correct_drug_spelling(text)\n",
        "\n",
        "    # Remove stopwords if specified\n",
        "    if remove_stops:\n",
        "        standard_stopwords = set(stopwords.words('english'))\n",
        "        text = remove_stopwords(text, standard_stopwords, custom_stopwords)\n",
        "\n",
        "    # Ensure clean whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "QijfOVOLkx02"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_json_file(input_file_path, output_file_path, fields_to_process=None,\n",
        "                     preserve_case=False, keep_punctuation=True, remove_stops=True):\n",
        "    \"\"\"\n",
        "    Process text fields in a JSON file.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Path to the input JSON file\n",
        "        output_file_path (str): Path to save the processed JSON file\n",
        "        fields_to_process (list): List of specific fields to process\n",
        "        preserve_case (bool): Whether to preserve the original case\n",
        "        keep_punctuation (bool): Whether to keep biomedically relevant punctuation\n",
        "        remove_stops (bool): Whether to remove stopwords\n",
        "    \"\"\"\n",
        "    # Define custom stopwords for biomedical documents\n",
        "    custom_stopwords = [\n",
        "        \"Warnings\", \"Precautions\", \"Use\", \"Specific\", \"Populations\",\n",
        "        \"see\", \"contraindications\", \"indications\", \"dosage\", \"administration\",\n",
        "        \"adverse\", \"reactions\", \"drug\", \"interactions\", \"clinical\", \"studies\"\n",
        "    ]\n",
        "\n",
        "    # Load the JSON file\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # If specific fields are provided, only process those\n",
        "    if fields_to_process:\n",
        "        for field in fields_to_process:\n",
        "            if field in data and isinstance(data[field], str):\n",
        "                # Store original field value\n",
        "                data[f\"{field}_original\"] = data[field]\n",
        "\n",
        "                # Apply text preprocessing\n",
        "                data[field] = preprocess_text(\n",
        "                    data[field],\n",
        "                    preserve_case=preserve_case,\n",
        "                    keep_punctuation=keep_punctuation,\n",
        "                    remove_stops=remove_stops,\n",
        "                    custom_stopwords=custom_stopwords\n",
        "                )\n",
        "    else:\n",
        "        # Process all string fields in the JSON\n",
        "        processed_data = process_json_object(\n",
        "            data,\n",
        "            preserve_case=preserve_case,\n",
        "            keep_punctuation=keep_punctuation,\n",
        "            remove_stops=remove_stops,\n",
        "            custom_stopwords=custom_stopwords\n",
        "        )\n",
        "        data = processed_data\n",
        "\n",
        "    # Save the processed JSON\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Processed JSON saved to {output_file_path}\")"
      ],
      "metadata": {
        "id": "3s1747pVk09i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_json_object(obj, preserve_case=False, keep_punctuation=True,\n",
        "                       remove_stops=True, custom_stopwords=None):\n",
        "    \"\"\"\n",
        "    Recursively process a JSON object, preprocessing text fields.\n",
        "\n",
        "    Args:\n",
        "        obj: JSON object (dict, list, or primitive value)\n",
        "        preserve_case (bool): Whether to preserve the original case\n",
        "        keep_punctuation (bool): Whether to keep biomedically relevant punctuation\n",
        "        remove_stops (bool): Whether to remove stopwords\n",
        "        custom_stopwords (list): Custom stopwords to remove\n",
        "\n",
        "    Returns:\n",
        "        The processed JSON object\n",
        "    \"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        result = {}\n",
        "        for key, value in obj.items():\n",
        "            if isinstance(value, str):\n",
        "                # Preprocess text fields\n",
        "                result[f\"{key}_original\"] = value\n",
        "                result[key] = preprocess_text(\n",
        "                    value,\n",
        "                    preserve_case=preserve_case,\n",
        "                    keep_punctuation=keep_punctuation,\n",
        "                    remove_stops=remove_stops,\n",
        "                    custom_stopwords=custom_stopwords\n",
        "                )\n",
        "            else:\n",
        "                # Recursively process non-string fields\n",
        "                result[key] = process_json_object(\n",
        "                    value,\n",
        "                    preserve_case=preserve_case,\n",
        "                    keep_punctuation=keep_punctuation,\n",
        "                    remove_stops=remove_stops,\n",
        "                    custom_stopwords=custom_stopwords\n",
        "                )\n",
        "        return result\n",
        "    elif isinstance(obj, list):\n",
        "        return [process_json_object(\n",
        "            item,\n",
        "            preserve_case=preserve_case,\n",
        "            keep_punctuation=keep_punctuation,\n",
        "            remove_stops=remove_stops,\n",
        "            custom_stopwords=custom_stopwords\n",
        "        ) for item in obj]\n",
        "    else:\n",
        "        # Return primitive values unchanged\n",
        "        return obj"
      ],
      "metadata": {
        "id": "xl_tlUK4k6lP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"sample_data/fe49a0d2-1f44-446c-9144-56ba9ca2cd6a.json\"  # Replace with your input file\n",
        "output_file = \"sample_data/processed_drug_data.json\" # Custom stopwords for specific fields\n",
        "\n",
        "# Process only specific fields\n",
        "fields_to_process = [\"contraindications\", \"indications\", \"warningsAndPrecautions\", \"adverseReactions\"]\n",
        "\n",
        "# Process the JSON file\n",
        "process_json_file(\n",
        "    input_file,\n",
        "    output_file,\n",
        "    fields_to_process=fields_to_process,\n",
        "    preserve_case=False,\n",
        "    keep_punctuation=True,\n",
        "    remove_stops=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32FODsOlC79",
        "outputId": "f1cd43f2-00be-4979-cb67-9047545320db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed JSON saved to sample_data/processed_drug_data.json\n"
          ]
        }
      ]
    }
  ]
}